{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d33022bb",
   "metadata": {},
   "source": [
    "# Projet BDDR\n",
    "### Binôme :  Zeynep BALIKCI et Mariama MBAYE\n",
    "\n",
    "Pour notre application, nous avons un socle minimal de requêtes:\n",
    "1. Liste d'articles par thématique et sous-thématique.\n",
    "2. Histogramme d'articles publiés par date, semaine, et mois.\n",
    "3. Liste de thématiques\n",
    "4. Nombre de publications par labo/institution.\n",
    "5. Liste de journaux par nombre  et type de publications.\n",
    "\n",
    "### Analyse des données\n",
    "\n",
    "Après étude du jeux de données telechargé sur Kaggle, nous nous sommes rendus comptes que les données nécesaires à nos requêtes se trouvent dans le fichier metadata.csv, les dossiers /document_parses/pdf_json et /document_parses/pmc_json, et enfin le dossier /Kaggle/target_tables.\n",
    "\n",
    "Pour les requêtes 1 et 3, nous avons récupérer ces données à partir du dossier /Kaggle/target_tables : le theme est le nom du dossier et les sous_themes le nom des fichiers csv se trouvant dans chaque dossier/theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2080ca6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theme='POPULATION'\n",
      "theme='RELEVANT FACTORS'\n",
      "theme='PATIENT DESCRIPTIONS'\n",
      "theme='MODELS AND OPEN QUESTIONS'\n",
      "theme='MATERIALS'\n",
      "theme='DIAGNOSTICS'\n",
      "theme='THERAPEUTICS INTERVENTIONS AND CLINICAL STUDIES'\n",
      "theme='RISK FACTORS'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "chemin_archive =\"/users/2023/ds1/share/CORD-19\"\n",
    "chemin_tables=f'{chemin_archive}/Kaggle/target_tables'\n",
    "elements = os.listdir(chemin_tables)\n",
    "dossiers = [element for element in elements if os.path.isdir(os.path.join(chemin_tables, element))]\n",
    "for dossier in dossiers[1:-1]:\n",
    "    theme=(dossier[2:].replace(\"_\",\" \")).upper()   # le theme est le nom du dossier\n",
    "    print(f'{theme=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cea2317",
   "metadata": {},
   "source": [
    "Pour la requête 5 (type de publications), ces données se trouvent dans une colonne des csv dans les  dossier-themes.\n",
    "\n",
    "Mais la liste de journaux ? Et la date de publication ? Ces données se trouvent dans le fichier metadata.csv (colonnes publish_time et journal) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99e15292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cord_uid', 'sha', 'source_x', 'title', 'doi', 'pmcid', 'pubmed_id',\n",
       "       'license', 'abstract', 'publish_time', 'authors', 'journal', 'mag_id',\n",
       "       'who_covidence_id', 'arxiv_id', 'pdf_json_files', 'pmc_json_files',\n",
       "       'url', 's2_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF=pd.read_csv(f'{chemin_archive}/metadata.csv')\n",
    "DF.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76c8562",
   "metadata": {},
   "source": [
    "Finalement, pour la requête 4, les affiliations des auteurs ne se trouvent que dans les fichiers du dossier /document_parses/pdf_json. Nous avons bien vérifier qu'il n'y avait pas les affiliations dans les fichiers du dossier /document_parses/pmc_json:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd758e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affiliation_pmc=2401600\n",
      "no_affiliation_pmc=0\n"
     ]
    }
   ],
   "source": [
    "chemin1 = f'{chemin_archive}/document_parses/pmc_json'\n",
    "elements1 = os.listdir(chemin1)\n",
    "\n",
    "files_load=0\n",
    "no_affiliation_pmc=0\n",
    "affiliation_pmc=0\n",
    "for element in elements1:\n",
    "    with open(f'{chemin1}/{element}', 'r') as f:\n",
    "        data = json.load(f)\n",
    "        files_load+=1\n",
    "        a=data['metadata']['authors']\n",
    "    if len(a)!=0:\n",
    "        for i in range(len(a)):\n",
    "            if len(data['metadata']['authors'][i]['affiliation'])!=0:\n",
    "                affiliation_pmc+=1\n",
    "            else:\n",
    "                no_affiliation_pmc+=1\n",
    "print(f'{files_load=}')\n",
    "print(f'{affiliation_pmc=}')\n",
    "print(f'{no_affiliation_pmc=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3230c52f",
   "metadata": {},
   "source": [
    "Est-ce qu'on peut récupérer les noms des auteurs qu'à partir du fichier metadata.csv ?\n",
    "\n",
    "Nous avons essayer de vérifier s'il y avait le même nombre d'auteurs dans DF\\['authors'\\] et dans les fichiers .json du dossier /document_parses/pmc_json\n",
    "\n",
    "Il y a DF\\['pmc_json_files'\\], donc on peut accéder au dossier directement à partir du fichier metadata.csv. Mais est-ce que ces fichiers de la colonne 'pmc_json_files' existe ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dcf8492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(elements1) == len(DF['pmc_json_files'].unique())-1  #le -1 c'est pour la valeur NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b931ef5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pmc_files_load=315742\n",
      "no_pmc_files=[]\n"
     ]
    }
   ],
   "source": [
    "no_pmc_files=[]\n",
    "pmc_files_load=0\n",
    "pmc_files=DF['pmc_json_files']\n",
    "for file in pmc_files:\n",
    "    if type(file)==str:     # car NaN est de type float\n",
    "        try:\n",
    "            with open(f'{chemin_archive}/{file}', 'r') as f:\n",
    "                data = json.load(f)\n",
    "                pmc_files_load+=1\n",
    "        except:\n",
    "            no_pmc_files.append(file)\n",
    "print(f'{pmc_files_load=}')\n",
    "print(f'{no_pmc_files=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0260fbd9",
   "metadata": {},
   "source": [
    "Donc on a bien tous les fichiers du DF\\['pmc_json_files'\\] qui existe et sont uniques.\n",
    "\n",
    "Nous avons fait pareil pour le DF\\['pdf_json_files'\\], mais pour certains articles il y en avait 2 ou même 3 fichiers pdf_json_files séparer par un ';'\n",
    "\n",
    "Mais tous les fichiers existe, même si certains se repète, on accède à tous les fichiers .json du dossier /document_parses/pdf_json\n",
    "\n",
    "Donc on peut accéder au fichier .json de chaque article directement à partir du fichier metadata.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bc63ae",
   "metadata": {},
   "source": [
    "Certains articles ont à la fois un fichier pmc_json_files et pdf_json_files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe4ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "double=0\n",
    "unique=0\n",
    "for i in range(len(df)):\n",
    "    if type(df['pdf_json_files'][i])==str and type(df['pmc_json_files'][i])==str:\n",
    "        double+=1\n",
    "    else :\n",
    "        unique+=1\n",
    "print(f'{double=}')\n",
    "print(f'{unique=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aa8543",
   "metadata": {},
   "source": [
    "On s'est donc demandé si il nous suffisait d'accéder au fichiers pdf_json_files à partir du fichier metadat.csv, pour optimiser le temps de peuplement, mais est-ce que les données dans pdf_json_files et les données dans pmc_json_files sont les mêmes ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f434d07c",
   "metadata": {},
   "source": [
    "Mais nous avons rencontré un autre problème avec le fichier metadata.csv car il y a beaucoup de valeurs manquantes DOI et le titre des article ne sont pas unique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88b5cc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1056660\n",
      "850367\n"
     ]
    }
   ],
   "source": [
    "print(len(DF))\n",
    "print(len(DF['title'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad3d499",
   "metadata": {},
   "source": [
    "Et finalement, nous nous sommes rendus comptes que certains auteurs avait 2 affiliation (laboratoire et institus), et que certains articles dans les sous_themes avait plusieurs 'Study Type'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c2f2d8",
   "metadata": {},
   "source": [
    "### Peuplement des tables\n",
    "\n",
    "Pour peupler les tables : theme, sous_themes, studytype, journal et affiliation nous avons choisi d'aller chercher directement les données sans les re-stocker dans un dataframe.\n",
    "\n",
    "Cette étape a été faite avec le module psycopg2 avant qu'on décide de créer un autre dataframe pour peupler les autres tables. Donc on a décidé de garder notre script, même si on aurait pu faire le peuplement de ces tables avec le dataframe qu'on va créer.\n",
    "\n",
    "Pour peupler les tables : articles, sous_themes_articles, studytype_articles, authors, articles_authors et affiliation_authors nous avons décider de reconstruire un autre dataframe à partir du fichier metadata.csv et en allant récupérer les données disponibles dans les fichiers .json pour chaque ligne de metadata.csv\n",
    "\n",
    "Colonnes de metadata qu'on garde : Title, abstract, publish_time, authors, journal, url\n",
    "\n",
    "Colonnes qu'on doit construire à partir des fichiers .json : Authors_pmc, Authors_pdf, Emails_pmc, Emails_pdf, Afilliation1, Country1, Affiliation2, Country2.\n",
    "\n",
    "Colonnes qu'on doit construire à partir des fichiers sous_themes.csv : sous_themes et Studytype\n",
    "\n",
    "Cette dataframe sera converti en fichier .csv pour que ça soit plus pratique et ne pas créer un dataframe à chaque lancement du peuplement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ac1f2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Froissart, Remy; Roze, Denis; Uzest, Marilyne; Galibert, Lionel; Blanc, Stephane; Michalakis, Yannis\n",
      "document_parses/pmc_json/PMC1054884.xml.json\n",
      "Froissart, Remy\n",
      "Roze, Denis\n",
      "Uzest, Marilyne\n",
      "Galibert, Lionel\n",
      "Blanc, Stephane\n",
      "Michalakis, Yannis\n",
      "Hull, Roger\n"
     ]
    }
   ],
   "source": [
    "Authors_pmc=[]\n",
    "Authors_metadata=[]\n",
    "\n",
    "for k in range(500):\n",
    "    auteurs_metadata=[]\n",
    "    auteurs_pmc=[]\n",
    "    ligne=DF['authors'][k]\n",
    "    file=DF['pmc_json_files'][k]\n",
    "    if type(ligne)==str:\n",
    "        try :\n",
    "            for author in ligne.split(';'):\n",
    "                if author.startswith(' '):\n",
    "                    a=author[1:]\n",
    "                    Authors_metadata.append(a)\n",
    "                    auteurs_metadata.append(a)\n",
    "                else:\n",
    "                    Authors_metadata.append(author)\n",
    "                    auteurs_metadata.append(author)\n",
    "        except:\n",
    "            Authors_metadata.append(ligne)\n",
    "            auteurs_metadata.append(ligne)\n",
    "    if type(file)==str:\n",
    "        with open(f'{chemin_archive}/{file}','r') as f:\n",
    "            data=json.load(f)\n",
    "            L=data['metadata']['authors']\n",
    "            if len(L)!=0:\n",
    "                for i in range(len(L)):\n",
    "                    name=L[i]['last']+', '+L[i]['first']\n",
    "                    Authors_pmc.append(name)\n",
    "                    auteurs_pmc.append(name)\n",
    "    if len(auteurs_pmc)!=len(auteurs_metadata):\n",
    "        print(ligne)\n",
    "        print(file)\n",
    "        if type(file)==str:\n",
    "            with open(f'{chemin_archive}/{file}','r') as f:\n",
    "                data=json.load(f)\n",
    "                L=data['metadata']['authors']\n",
    "                for i in range(len(L)):\n",
    "                    print(L[i]['last']+', '+L[i]['first'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "260ef9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document_parses/pmc_json/PMC59574.xml.json\n",
      "['Fagan, Karen', 'McMurtry, Ivan', 'Rodman, David']\n",
      "document_parses/pdf_json/348055649b6b8cf2b9a376498df9bf41f7123605.json\n",
      "[]\n",
      "3\n",
      "document_parses/pmc_json/PMC306617.xml.json\n",
      "['Ploubidou, Aspasia', 'Moreau, Violaine', 'Ashman, Keith', 'Reckmann, Inge', 'González, Cayetano', 'Way, Michael']\n",
      "document_parses/pdf_json/44102e3e69e70ad2a73e753133283334ce1f8736.json\n",
      "['Ploubidou, Aspasia', 'Moreau, Violaine', 'Ashman, Keith', 'Reckmann, Inge', 'Gonza, Cayetano', 'Lez, Â', 'Way, Michael']\n",
      "13\n",
      "document_parses/pmc_json/PMC468896.xml.json\n",
      "['Verheij, Joanne', 'Groeneveld, AB', 'Beishuizen, Albertus', 'Lingen, Arthur', 'Simoons-Smit, Alberdina', 'van Schijndel, Rob']\n",
      "document_parses/pdf_json/6a8ac55ea2a1fbd99deb683e24dd986e55e707b3.json\n",
      "['Verheij, Joanne', 'Ab, Johan', 'Groeneveld, ', 'Beishuizen, Albertus', 'Van Lingen, Arthur', 'Simoons-Smit, Alberdina', 'Jm, Rob', 'Van Schijndel, Strack']\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "for k in range(20):\n",
    "    auteurs_pdf=[]\n",
    "    auteurs_pmc=[]\n",
    "    file_pmc=DF['pmc_json_files'][k]\n",
    "    file_pdf=DF['pdf_json_files'][k]\n",
    "    if type(file_pmc)==str:\n",
    "        with open(f'{chemin_archive}/{file_pmc}','r') as f:\n",
    "            data=json.load(f)\n",
    "            L=data['metadata']['authors']\n",
    "            if len(L)!=0:\n",
    "                for i in range(len(L)):\n",
    "                    name=L[i]['last']+', '+L[i]['first']\n",
    "                    auteurs_pmc.append(name)\n",
    "    if type(file_pdf)==str:\n",
    "        if ';' in file_pdf:\n",
    "            liste_file=file_pdf.split(';')\n",
    "            for fil in liste_file:\n",
    "                if fil.startswith(' '):\n",
    "                    fi=fil[1:]\n",
    "                else:\n",
    "                    fi=fil\n",
    "                try:\n",
    "                    with open(f'{chemin_archive}/{fi}', 'r') as f:\n",
    "                        data = json.load(f)\n",
    "                        L=data['metadata']['authors']\n",
    "                        if len(L)!=0:\n",
    "                            for i in range(len(L)):\n",
    "                                name=L[i]['last']+', '+L[i]['first']\n",
    "                                auteurs_pdf.append(name)\n",
    "                except:\n",
    "                    print(fi)\n",
    "        else:\n",
    "            try:\n",
    "                with open(f'{chemin_archive}/{file_pdf}', 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    L=data['metadata']['authors']\n",
    "                    if len(L)!=0:\n",
    "                        for i in range(len(L)):\n",
    "                            name=L[i]['last']+', '+L[i]['first']\n",
    "                            auteurs_pdf.append(name)\n",
    "            except:\n",
    "                print(file_pdf)\n",
    "    \n",
    "    if len(auteurs_pmc)!=len(auteurs_pdf):\n",
    "        print(file_pmc)\n",
    "        print(auteurs_pmc)\n",
    "        print(file_pdf)\n",
    "        print(auteurs_pdf)\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5c90e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document_parses/pdf_json/4eb6e165ee705e2ae2a24ed2d4e67da42831ff4a.json\n",
      "document_parses/pdf_json/d4f0247db5e916c20eae3f6d772e8572eb828236.json\n",
      "75\n",
      "['Malanoski, Anthony', 'Lin, Baochuan', 'Wang, Zheng', 'Schnur, Joel', 'Stenger, David']\n",
      "75\n",
      "[]\n",
      "document_parses/pdf_json/ad9ac0ac5e7da097253fd545b56e2b15ee9de34f.json\n",
      "document_parses/pdf_json/daee7f7d31f4bf1c0ef883bcd6c124b6e94cbee7.json\n",
      "76\n",
      "['Mccrate, Nina', 'Varner, Mychel', 'Kim, Kenneth', 'Nagan, Maria', 'Uuu, [', 'Yarian, M', 'Marszalek, E', 'Sochacka, A', 'Malkiewicz, R', 'Guenther, A', 'Miskiewicz, P']\n",
      "76\n",
      "['Mccrate, Nina', 'Varner, Mychel', 'Kim, Kenneth', 'Nagan, Maria']\n",
      "document_parses/pdf_json/52566dccb4bd8044edc87b1a0aa268320a6ea3d4.json\n",
      "document_parses/pdf_json/8b39433dd865c0f71c7b2f333e1f506b73d722f1.json\n",
      "77\n",
      "['Kutyavin, Igor', 'Milesi, Dave', 'Belousov, Yevgeniy', 'Podyminogin, Mikhail', 'Vorobiev, Alexei', 'Gorn, Vladimir', 'Lukhtanov, Eugeny', 'Vermeulen, Nicolaas', 'Mahoney, Walt']\n",
      "77\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for k in range(100):\n",
    "    auteurs_pdf=[]\n",
    "    file_pdf=DF['pdf_json_files'][k]\n",
    "    if type(file_pdf)==str:\n",
    "        if ';' in file_pdf:\n",
    "            liste_file=file_pdf.split(';')\n",
    "            for fil in liste_file:\n",
    "                auteurs=[]\n",
    "                if fil.startswith(' '):\n",
    "                    try:\n",
    "                        print(fil[1:])\n",
    "                        with open(f'{chemin_archive}/{fil[1:]}', 'r') as f:\n",
    "                            \n",
    "                            data = json.load(f)\n",
    "                            L=data['metadata']['authors']\n",
    "                            if len(L)!=0:\n",
    "                                for i in range(len(L)):\n",
    "                                    name=L[i]['last']+', '+L[i]['first']\n",
    "                                    auteurs.append(name)\n",
    "                                    \n",
    "                    except:\n",
    "                        print(fil,'e')\n",
    "                    \n",
    "                else:\n",
    "                    try:\n",
    "                        print(fil)\n",
    "                        with open(f'{chemin_archive}/{fil}', 'r') as f:\n",
    "                            data = json.load(f)\n",
    "                            L=data['metadata']['authors']\n",
    "                            if len(L)!=0:\n",
    "                                for i in range(len(L)):\n",
    "                                    name=L[i]['last']+', '+L[i]['first']\n",
    "                                    auteurs.append(name)\n",
    "                                    \n",
    "                    except:\n",
    "                        print(fil,'e')\n",
    "                auteurs_pdf.append(auteurs)\n",
    "    for j in auteurs_pdf:\n",
    "        print(k)\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8e68678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401270\n",
      "401214\n"
     ]
    }
   ],
   "source": [
    "files_pdf=[]\n",
    "for k in range(len(DF)):\n",
    "    file_pdf=DF['pdf_json_files'][k]\n",
    "    if type(file_pdf)==str:\n",
    "        if ';' in file_pdf:\n",
    "            liste_file=file_pdf.split(';')\n",
    "            for fil in liste_file:\n",
    "                if fil.startswith(' '):\n",
    "                    files_pdf.append(fil[1:])\n",
    "                else:\n",
    "                    files_pdf.append(fil)\n",
    "        else:\n",
    "            files_pdf.append(file_pdf)\n",
    "print(len(files_pdf))\n",
    "print(len(set(files_pdf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e2a935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
